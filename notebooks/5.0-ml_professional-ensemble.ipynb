{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5970f1a4",
   "metadata": {},
   "source": [
    "# M√©todos de Ensamble Aplicados a Clasificaci√≥n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc4de2d",
   "metadata": {},
   "source": [
    "üìå Probar diferentes estimadores y llegar a una sola conclusi√≥n a trav√©s de un consenso. <br>\n",
    "\n",
    "En lugar de depender de un solo modelo para hacer una predicci√≥n, se combinan las predicciones de varios modelos para obtener un resultado final m√°s preciso y robusto.\n",
    "\n",
    "**Caracter√≠sticas de los m√©todos de ensamble**\n",
    "\n",
    "1. Combinar diferentes m√©todos (algoritmos/modelos) de ML con diferentes configuraciones y aplicar un m√©todo para lograr un consenso.\n",
    "2. Probar diferentes modelos con diferentes par√°metros.\n",
    "\n",
    "> Analog√≠a  ‚Äú*sabidur√≠a de la multitud*‚Äù. Si le preguntas a un solo experto una pregunta dif√≠cil, puedes obtener una buena respuesta. Pero si le preguntas una pregunta dif√≠cil a un comit√© de diez expertos y combinas sus opiniones, es mucho m√°s probable que la respuesta final sea excelente y menos sensible a los sesgos o errores de un solo individuo.\n",
    "\n",
    "\n",
    "> üí° En clasificaci√≥n: <br>\n",
    "\tExpertos = Modelos individuales.\n",
    "\n",
    "</aside>\n",
    "\n",
    "**üéØ Objetivo principal de los ensambles:**\n",
    "\n",
    "- **Reducir la varianza** (overfitting): Ayuda a generalizar mejor.\n",
    "- **Reducir el sesgo** (bias): Ayuda a que el modelo no sea demasiado simple.\n",
    "\n",
    "**Estrategias**\n",
    "\n",
    "1. **Bagging** üéí (Bootstrap AGGregation): Utiliza a varios ‚Äúexpertos‚Äù para evaluar los diferentes modelos, cada uno califica en paralelo, luego se intenta lograr un consenso,  mediante una formula: conteo de votos √≥ un promedio. <br>\n",
    "üéØ **Objetivo**: Reducir la varianza y evitar el overfitting \n",
    "    1. Crea particiones aleatorias (uniformes y con reemplazo) del dataset original.\n",
    "    1. Se construyen modelos para cada una de las particiones.<br>\n",
    "    üì¢ Pueden ser el mismo modelo o bien modelos diferentes.\n",
    "    1. La respuesta final es la combinaci√≥n entre todas las respuestas individuales.\n",
    "\n",
    "2. **Boosting** üöÄ impulsar / propulsar: Se centra en mejorar el rendimiento mediante aprendizaje en secuencia, cada modelo intenta corregir el los errores del modelo anterior. <br>\n",
    "üéØ Objetivo: Reducir el sesgo y construir un modelo fuerte de manera secuencial.\n",
    "    1. Entrenamiento secuencial.\n",
    "    2. Busca fortalecer gradualmente un modelo utilizando el error residual del modelo anterior.\n",
    "    3. El resultado final se consigue por consenso entre todos los modelos.\n",
    "\n",
    "\n",
    "**M√©todos de Bagging:**\n",
    "- Random Forest ‚Üí Utiliza varios √°rboles de decisi√≥n\n",
    "- Voting Classifier / Regressor\n",
    "\n",
    "**M√©todos de Boosting:**\n",
    "- AdaBoost\n",
    "- Gradient Tree Boosting\n",
    "- XGBoost (librer√≠a externa a scikit-learn)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71e2a17",
   "metadata": {},
   "source": [
    "## Implementaci√≥n con Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684d812e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\", role=\"alert\">\n",
    "    <h5>‚ö†Ô∏è</h5>\n",
    "    <p>\n",
    "      El ejemplo desglosado a continuaci√≥n sigue paso a paso la implementaci√≥n que se realiz√≥ en el curso, solo con unos detalles adicionales. <br>\n",
    "\t\t\tEspecificamente en la clase <a href=\"https://platzi.com/cursos/scikitlearn/preparacion-de-datos-para-implementar-metodos-de-e/\"> \n",
    "\t\t\t\tImplementaci√≥n de Baggin Classifier</a>\n",
    "\t\t\t\t<br>\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1269600",
   "metadata": {},
   "source": [
    "Librer√≠as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "492d932e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# M√≥delo\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# M√©todo de ensamble\n",
    "from sklearn.ensemble import BaggingClassifier, GradientBoostingClassifier\n",
    "\n",
    "# Dividir el dataset en entrenamiento y pruebas\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Metricas\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d19d31fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run 0.0-ml_professional-setup.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2987293",
   "metadata": {},
   "source": [
    "Carga del dataset Heart Disease:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50f5b122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>203</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>148</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>294</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   52    1   0       125   212    0        1      168      0      1.0      2   \n",
       "1   53    1   0       140   203    1        0      155      1      3.1      0   \n",
       "2   70    1   0       145   174    0        1      125      1      2.6      0   \n",
       "3   61    1   0       148   203    0        1      161      0      0.0      2   \n",
       "4   62    0   0       138   294    1        1      106      0      1.9      1   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   2     3       0  \n",
       "1   0     3       0  \n",
       "2   0     3       0  \n",
       "3   1     3       0  \n",
       "4   3     2       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = path.data_raw_dir(\"heart.csv\")\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59a9099",
   "metadata": {},
   "source": [
    "Separamos el dataframe en features de entrenamiento y target:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80240f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features' shape: (1025, 13)\n",
      "Tartge's shape: (1025,)\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(columns=[\"target\"])\n",
    "y = df[\"target\"]\n",
    "\n",
    "print(f\"Features' shape: {X.shape}\")\n",
    "print(f\"Tartge's shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5283d5aa",
   "metadata": {},
   "source": [
    "Divisi√≥n de datos en entrenamiento y pruebas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4316b19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.35, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c42e857",
   "metadata": {},
   "source": [
    "Entrenamiento del modelo K-Neighbors:\n",
    "\n",
    "\n",
    "üìå **NOTA**: K-Neighbors es un clasificador poco robusto, por lo que utilizarlo para ejemplificar las capacidades de Bagging con clasificadores \"d√©biles\" se presta para este ejercicio, donde comparamos la precisi√≥n en las predicciones entre estos modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2d95f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "kn_class = KNeighborsClassifier().fit(X_train, y_train)\n",
    "kn_pred = kn_class.predict(X_test)\n",
    "kn_accuracy =  accuracy_score(kn_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce1a120",
   "metadata": {},
   "source": [
    "Entrenamiento de BagginClassifier utilizando el modelo K-Neighbors como estimador base:\n",
    "- `estimator`: Modelo/esitmador base con el cu√°l se realizar√° la \n",
    "- `n_estimators`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb3b38c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bagg_class = BaggingClassifier(estimator=KNeighborsClassifier(), n_estimators=50, random_state=42).fit(X_train, y_train)\n",
    "bagg_pred = bagg_class.predict(X_test)\n",
    "bagg_accuracy = accuracy_score(y_test, bagg_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c85f1c2",
   "metadata": {},
   "source": [
    "Entrenamiento de GradientBoostingClassifier:\n",
    "- `n_estimators`: N√∫mero de √°rboles de decisi√≥n que se entrenar√°n uno detras de otro para hacer las predicciones y obtener resultados optimos. \n",
    "\n",
    "\n",
    "\n",
    "üìå **NOTA**: Gradient Boosting utiliza √°rboles de decisi√≥n de fondo, lo que hace es crear √°rboles peque√±os con pocas hojas para realizar la clasificaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c42f4500",
   "metadata": {},
   "outputs": [],
   "source": [
    "boost = GradientBoostingClassifier(n_estimators=50, random_state=42).fit(X_train, y_train)\n",
    "boost_pred = boost.predict(X_test)\n",
    "boost_accuracy = accuracy_score(y_test, boost_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4dd64c5",
   "metadata": {},
   "source": [
    "Comparamos la exactitud de los modelos a partir de su `Accuracy Score`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40790da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KN Accuracy: 69.08%\n",
      "BaggingClassifier Accuracy: 73.26%\n",
      "GradientBoostingClassifier Accuracy: 93.59%\n"
     ]
    }
   ],
   "source": [
    "print(f\"KN Accuracy: {kn_accuracy:.2%}\")\n",
    "print(f\"BaggingClassifier Accuracy: {bagg_accuracy:.2%}\" )\n",
    "print(f\"GradientBoostingClassifier Accuracy: {boost_accuracy:.2%}\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc1df64",
   "metadata": {},
   "source": [
    "Para este ejemplo pr√°ctico utilizando el dataset Heart Disease, llegamos a las observaciones descritas en los siguientes p√°rrafos, sin embargo debemos tener en cuenta que el uso de los estimadores, los m√©todos de ensamble y sus par√°metros, dependen de los datos que tendamos y el objetivo del proyecto, por ende, √©ste ejemplo puede que no funcione adecuadamente con un dataset distinto.\n",
    "\n",
    "\n",
    "La precisi√≥n obtenida con Baggin Classifier utilizando a K-Neighbors como estimador base nos d√≠o un resultado de 4.21% mayor que el modelo por si solo. Aun que la diferencia no es muy alta, nos permite observar con claridad que el uso de ensambles pueden ayudarnos a robustecer nuestros modelos.\n",
    "\n",
    "Por otra parte, al utilizar Gradient Boosting Classifier, la presici√≥n se dispara llegando a +93%, √©ste resultado se debe a que el Graddinet Gradient Boosting utiliza peque√±os arboles de decisi√≥n entrenados que robustecen el entrenamiento del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17662110",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_professional",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
